{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Importing libraries. Make sure you have these in your environment before you do anything!\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import sklearn\r\n",
    "import tensorflow as tf\r\n",
    "# import torch (if you're into that)\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Importing the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "df_10k = pd.read_csv(\"tmnist_10k.csv\")\r\n",
    "df_1k = pd.read_csv(\"tmnist_1k_unlb.csv\")\r\n",
    "\r\n",
    "print(\"Shape of the 10k df: \" + str(df_10k.shape) + \"\\n\")\r\n",
    "print(df_10k.head())\r\n",
    "\r\n",
    "print(\"\\n\\nShape of the 1k df: \" + str(df_1k.shape) + \"\\n\")\r\n",
    "print(df_1k.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Shape of the 10k df: (10000, 787)\n",
      "\n",
      "   Unnamed: 0                 names labels  1  2  3  4  5  6  7  ...  775  \\\n",
      "0           0         Salsa-Regular      6  0  0  0  0  0  0  0  ...    0   \n",
      "1           1  MouseMemoirs-Regular      D  0  0  0  0  0  0  0  ...    0   \n",
      "2           2     Creepster-Regular      f  0  0  0  0  0  0  0  ...    0   \n",
      "3           3      SeoulNamsan-Ligh      /  0  0  0  0  0  0  0  ...    0   \n",
      "4           4  HachiMaruPop-Regular      F  0  0  0  0  0  0  0  ...    0   \n",
      "\n",
      "   776  777  778  779  780  781  782  783  784  \n",
      "0    0    0    0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0    0    0    0  \n",
      "2    0    0    0    0    0    0    0    0    0  \n",
      "3    0    0    0    0    0    0    0    0    0  \n",
      "4    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 787 columns]\n",
      "\n",
      "\n",
      "Shape of the 1k df: (1000, 786)\n",
      "\n",
      "   Unnamed: 0                 names  1  2  3  4  5  6  7  8  ...  775  776  \\\n",
      "0           0      WendyOne-Regular  0  0  0  0  0  0  0  0  ...    0    0   \n",
      "1           1    Engagement-Regular  0  0  0  0  0  0  0  0  ...    0    0   \n",
      "2           2       NotoSans-Italic  0  0  0  0  0  0  0  0  ...    0    0   \n",
      "3           3  HindColombo-SemiBold  0  0  0  0  0  0  0  0  ...    0    0   \n",
      "4           4           Dosis[wght]  0  0  0  0  0  0  0  0  ...    0    0   \n",
      "\n",
      "   777  778  779  780  781  782  783  784  \n",
      "0    0    0    0    0    0    0    0    0  \n",
      "1    0    0    0    0    0    0    0    0  \n",
      "2    0    0    0    0    0    0    0    0  \n",
      "3    0    0    0    0    0    0    0    0  \n",
      "4    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[5 rows x 786 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploratory Data Analysis\r\n",
    "Take some time to understand what data you're working with. Maybe even try visualizing some of the images.\r\n",
    "\r\n",
    "What's the distribution of the labels? Is there any missing data? What kinds of values are you working with?\r\n",
    "\r\n",
    "Understanding your data is a key step to building an exceptional ML model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing\r\n",
    "Your data will need to be worked with a little before it's ready to be fed into a model.\r\n",
    "\r\n",
    "Here are a couple things you could look into (not an exhaustive list):\r\n",
    "1. Normalize\r\n",
    "2. Deal with missing/null values\r\n",
    "3. Reshape data\r\n",
    "4. Encode columns\r\n",
    "5. Split data into various train/validation/test sets\r\n",
    "6. Dimensionality reduction???"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Basic Model Building\r\n",
    "What if all you need is a logistic regression? No need to spend time meticulously making some crazy CNN.\r\n",
    "\r\n",
    "Maybe you have a couple hypothesis about which data transformations will give better results. This is a great time to test them out before you get to building some models that take a while to train."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation\r\n",
    "How do you want to check your model's quality? Accuracy is the final metric being judged, but you may need more insight on where your model's going wrong to take up those last couple percent.\r\n",
    "Things to try might include:\r\n",
    "1. Confusion Matricies\r\n",
    "2. Other kinds of performance metrics (Log loss, precision, recall, F1)\r\n",
    "3. Check for overfitting or underfitting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Iterating on the Model\r\n",
    "Make you model better or try new ones!\r\n",
    "Obviously you'll want to do similar evaluation tests to these models as well"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Output!\r\n",
    "You'll need to change a few things. Anything wrapped in < > will need to be changed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "judging_input = df_1k.drop(labels=[\"names\"], axis=1)\r\n",
    "\r\n",
    "# -- A couple basic ways to export your models to csv using various ML libraries. Make sure you fill in the blanks.\r\n",
    "\r\n",
    "# -- Tensorflow template --\r\n",
    "# judging_output = <tf model object>.predict(juding_input)\r\n",
    "# np.savetxt(\"adv_output_<team number>.csv\", judging_output, delimiter=\",\")\r\n",
    "\r\n",
    "# -- Pytorch template -- \r\n",
    "# <pytorch model object>.eval()\r\n",
    "# juding_input = Tensor([juding_input])\r\n",
    "# judging_output = <pytorch model object>(juding_input).detach().numpy()\r\n",
    "# np.savetxt(\"adv_output_<team number>.csv\", judging_output, delimiter=\",\")\r\n",
    "\r\n",
    "# -- sklearn template\r\n",
    "# judging_output = <sklearn model object>.predict(juding_input)\r\n",
    "# np.savetxt(\"adv_output_<team number>.csv\", judging_output, delimiter=\",\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "bc8ebe813587e5e35cd8e1eee8dc8c8c7b4d146f3c11a5a1453b36b24fab16bc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}